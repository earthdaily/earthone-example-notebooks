{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146c0193-10ec-4aab-82e5-38d6b432dadd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supervised ML on EarthOne Platform: Training a Random Forest Classifier\n",
    "__________________\n",
    "This example will demonstrate a typical pattern of generating training data for a supervised classifier using EarthOne Platform APIs.\n",
    "\n",
    "The general steps covered in this notebook are:\n",
    "* Read in a training dataset from [`Vector`](https://docs.earthone.earthdaily.com/earthdaily/earthone/vector/readme.html) containing simple land cover categories over the Austin, TX area \n",
    "* Visualize our study area and input layers in [`Dynamic Compute`](https://docs.earthone.earthdaily.com/api/dynamic-compute.html)\n",
    "* Define an asynchronous [`Function`](https://docs.earthone.earthdaily.com/earthdaily/earthone/compute/readme.html#earthdaily.earthone.compute.Function) which takes a tile key as an input and:\n",
    "    * Searches [`Catalog`](https://docs.earthone.earthdaily.com/earthdaily/earthone/catalog/readme.html) to raster data over the **nir**, **red**, and **green** bands of National Agricultural Imagery Program (NAIP) imagery\n",
    "    * Extracts intersecting features as raster masks\n",
    "    * Returns associated pixel values as lists\n",
    "    \n",
    "Move on to [02b Training a Supervised Classifier.ipynb](02b%20Training%20a%20Supervised%20Classifier.ipynb) to retrieve the results of the completed function and train a simple Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9ec79-8d88-4895-b23e-554d94c6f56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "import earthdaily.earthone as eo\n",
    "import earthdaily.earthone.compute\n",
    "import earthdaily.earthone.vector as eo_vector\n",
    "import earthdaily.earthone.dynamic_compute as dc\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely.geometry as sgeom\n",
    "from shapely import remove_repeated_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d994c8-78e6-4e56-9fb1-f0f22396afa3",
   "metadata": {},
   "source": [
    "Load global variables for reference throughout this example, including the NAIP product ID, a list of bands, a start and end date, resolution, and a name for our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e27f3f-dee5-4de7-9b7b-93eec03ce68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.load(file, yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15540a46-269f-4936-97a1-341ef9b27f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "major = sys.version_info.major\n",
    "minor = sys.version_info.minor\n",
    "compute_image = f\"python{major}.{minor}:latest\"\n",
    "compute_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ce091-6dc7-4a44-86ff-deb36992a28f",
   "metadata": {},
   "source": [
    "Next we retrieve a table of sample training features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c4a72-468c-4402-b7fe-67e669ad7420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = eo_vector.Table.get(config[\"training_table_name\"])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38feb-2e79-4c1c-996a-7c51e555c614",
   "metadata": {},
   "source": [
    "## Study Area - Austin, TX\n",
    "In the next few cells we will set up an interactive map frame to overlay our training feature collection on the input NAIP imagery. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbf227-f0e5-4ab9-b14f-17a526516a47",
   "metadata": {},
   "source": [
    "Setting up an interactive map, alongside center coordinates and zoom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf6083-6b36-43b0-99f5-fa45f82c6776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = dc.map\n",
    "m.center = 30.2552, -97.7689\n",
    "m.zoom = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692b029-2e82-4e9b-8e1c-5aefec586470",
   "metadata": {},
   "source": [
    "Create a mosaic of our NAIP imagery and visualize as a false color composite (FCC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949db953-15b9-4927-84b4-5fda2ce9df7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_mosaic = dc.Mosaic.from_product_bands(\n",
    "    config[\"product_id\"],\n",
    "    config[\"bands\"],\n",
    "    start_datetime=config[\"start\"],\n",
    "    end_datetime=config[\"end\"],\n",
    ")\n",
    "\n",
    "naip_mosaic.visualize(\"FCC\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fc94f-2664-47c6-94e2-6be3957730b2",
   "metadata": {},
   "source": [
    "Next visualize our input training table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913864a-8cf1-4c66-8ca0-a298c4ea08c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table.visualize(\n",
    "    \"Training Polygons\",\n",
    "    m,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b31a14-f764-4e3d-b348-2e9318044216",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating Training Data - Tiling\n",
    "As outlined above, the general steps to extract training data are as follows:\n",
    "* Splitting up the training AOI into tiles\n",
    "* For each tile we search NAIP imagery and extract all intersecting feature masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfce8b-cdf2-4414-9430-6918c81996ba",
   "metadata": {},
   "source": [
    "First, lets pull the data from the table and get a feel for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ca432-8381-4659-9961-ed6b21d2f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = table.collect()\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f968b52-f15c-4fa6-8c5f-ffd791c776fc",
   "metadata": {},
   "source": [
    "We have rows of data with a geometry column, a plain-text category, a category integer (so water maps to the value 3) and a uuid that uniquely identifies each row. Lets look at what the categories are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845825aa-2c77-4407-aac0-6ab2575ebfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(gdf)} features with the following categories: {gdf.category.unique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044271c-5086-43e3-8d93-d9618c65930f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b8f7f-496f-4501-9e78-8fbf3124829f",
   "metadata": {},
   "source": [
    "## Generating Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa305c9a-4001-418d-85aa-cbbb1f53fd4f",
   "metadata": {},
   "source": [
    "First we will search NAIP over a sample tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233baaa1-7b22-49e7-a0d6-8ccc51944e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geom = gdf.iloc[0]['geometry']\n",
    "aoi = eo.geo.AOI(geom, resolution=config['resolution_m'], crs='EPSG:3857')\n",
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2171bd-dc1a-4e1a-972d-3c93d064ece8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_ic = (\n",
    "    eo.catalog.Product.get(config[\"product_id\"])\n",
    "    .images()\n",
    "    .intersects(aoi)\n",
    "    .filter(config[\"start\"] <= eo.catalog.properties.acquired < config[\"end\"])\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85107b6e-b0d0-4de6-8653-2c3cf036f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "naip_arr = naip_ic.mosaic(config[\"bands\"], bands_axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac140e1-c977-4b2c-a817-32eb1efd7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(naip_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eaaa64-584d-43a0-b74b-87fcca023191",
   "metadata": {},
   "source": [
    "## Putting it All Together with Batch Compute\n",
    "Here we'll define a function which wraps all of the previously outlined methodology into a self-contained Python function. The inputs here are a single tile key and the overall steps are as follows:\n",
    "* Re-create a tile from the passed key\n",
    "* Retrieve the training features clipped to the input tile\n",
    "* Search NAIP over the input tile and retrieve the imagery as a geotiff\n",
    "* Perform the feature sampling method outlined above against the clipped features\n",
    "* Return the associated intersecting band values as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8d9d3-5021-45fa-b124-a982b3cb266c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pixel_values(\n",
    "    FEATURE_ID: str, \n",
    "    TABLE_ID: str, \n",
    "    START: str,\n",
    "    END: str, \n",
    "    BANDS: list):\n",
    "\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    import earthdaily.earthone as eo\n",
    "    import earthdaily.earthone.vector as eo_vector\n",
    "    import geopandas as gpd\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    print(f\"Processing {FEATURE_ID}\")\n",
    "\n",
    "    PRODUCT_ID = \"usda:naip:v1\"\n",
    "\n",
    "    # Pulling GDF from Vector\n",
    "    feature = eo_vector.Feature.get(f\"{TABLE_ID}:{FEATURE_ID}\").values\n",
    "\n",
    "    aoi = eo.geo.AOI(feature['geometry'], resolution=1.0, crs=\"EPSG:3857\")\n",
    "\n",
    "    print(\"Searching Images...\")\n",
    "    naip_ic = (\n",
    "        eo.catalog.Product.get(PRODUCT_ID)\n",
    "        .images()\n",
    "        .intersects(aoi)\n",
    "        .filter(START <= eo.catalog.properties.acquired < END)\n",
    "        .sort(\"acquired\")\n",
    "        .limit(None)\n",
    "    ).collect()\n",
    "\n",
    "    print(\"Downloaded GDF...\")\n",
    "    naip_ndarr = naip_ic.mosaic(\n",
    "        bands=BANDS,\n",
    "    )\n",
    "    print(\"Downloaded Imagery...\")\n",
    "\n",
    "    # Returning GDF as a dictionary, dropping geom column along the way:\n",
    "    # In practice, you could modify your own personal Table here:\n",
    "    out_data = {\"uuid\": FEATURE_ID, \"year\": START[:4],  \"data\": {}}\n",
    "    for i, band in enumerate(BANDS):\n",
    "        out_data['data'][band]=naip_ndarr[i].compressed().tolist()\n",
    "\n",
    "    out_data['data']['category_int']=np.full(naip_ndarr[0].compressed().shape, feature['category_int']).tolist()\n",
    "    out_data['data']['year']=np.full(naip_ndarr[0].compressed().shape, int(START[:4])).tolist()\n",
    "\n",
    "    print(\"Complete\")\n",
    "\n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06641fbc-6c34-460a-8cf5-9362d0f6d3ea",
   "metadata": {},
   "source": [
    "Now we format our input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65a3d2-1704-4231-9129-2a8169ab1ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = [[uuid, config[\"training_table_name\"], config['start'], config['end'], config['bands']] for uuid in gdf.uuid]\n",
    "len(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0da94d-227d-4632-80f3-667c41065f57",
   "metadata": {},
   "source": [
    "Now that it's all packaged up into a function, we can test it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f2e6e-29a7-4932-8a04-914d8b34ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_pixel_values(*args[0])\n",
    "pd.DataFrame(res['data']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b672fc-bf86-417e-979d-7d5c49e710ec",
   "metadata": {},
   "source": [
    "Once we are happy with the performance of our function we can save it to our Compute service.\n",
    "\n",
    "Note here that we must pass geopandas as a requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cd19a-840d-49a6-b759-5c9f7045eae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_func = eo.compute.Function(\n",
    "    get_pixel_values,\n",
    "    name=config[\"gen_data_func_name\"],\n",
    "    image=compute_image,\n",
    "    cpus=1,\n",
    "    memory=2,\n",
    "    timeout=300,\n",
    "    maximum_concurrency=20,\n",
    "    retry_count=1,\n",
    ")\n",
    "\n",
    "async_func.save()\n",
    "print(f\"Saved {async_func.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b7e77-92b1-4986-b357-bad826de7e9c",
   "metadata": {},
   "source": [
    "**_Take note of your Function ID!_**\n",
    "\n",
    "And finally map args to our Function to return a set of jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d6d76-21c6-4783-918c-a6dd7f2f7334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs = async_func.map(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64a26e-4def-4781-bf5a-45e18d5c0231",
   "metadata": {
    "tags": []
   },
   "source": [
    "Navigate to [earthone.earthdaily.com/compute](https://earthone.earthdaily.com/compute) to track your progress.\n",
    "\n",
    "Or wait programmatically via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5238dc-0c8a-47c6-b354-9640dc372d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5245a4-b5f4-4dcb-8597-757bd4be7f7f",
   "metadata": {},
   "source": [
    "Once this function completes, you can move on to [02b Training a Supervised Classifier.ipynb](02b%20Training%20a%20Supervised%20Classifier.ipynb) to retrieve the results and train our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa14599-a00f-4584-ba2e-32888f77d7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
